import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'src'))

import pytorch_lightning as pl
from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping, LearningRateMonitor
from pytorch_lightning.loggers import TensorBoardLogger
from pytorch_lightning.strategies import DDPStrategy
from data.datamodule import Flickr30kDataModule
from training.lightning_module import OpenVocabLightningModule

def main():
    # Config tá»‘i Æ°u cho hiá»‡u suáº¥t cao nháº¥t
    config = {
        'model': {
            'image_encoder': {
                'model_name': 'swin_tiny_patch4_window7_224',  # Model nháº¹ nháº¥t
                'pretrained': True,
                'out_dim': 256  # Dimension nhá» nháº¥t
            },
            'text_encoder': {
                'model_name': 'openai/clip-vit-base-patch32'
            },
            'fusion': {
                'dim': 256,
                'num_layers': 1,  # Chá»‰ 1 layer
                'num_heads': 4,   # Ãt heads hÆ¡n
                'text_dim': 512
            },
            'box_head': {
                'input_dim': 256,
                'hidden_dim': 128,
                'num_queries': 20  # Ãt queries hÆ¡n
            }
        },
        'lr': 5e-4,  # Learning rate cao hÆ¡n
        'weight_decay': 1e-4,
        'use_amp': True,  # Báº­t mixed precision
        'loss': {
            'lambda_cls': 0.3,     # Giáº£m classification loss
            'lambda_bbox': 5.0,
            'lambda_giou': 2.0,
            'lambda_sim': 0.1,     # Giáº£m similarity loss
            'temperature': 0.1,
            'region_dim': 256,
            'text_dim': 512
        }
    }
    
    # Data module vá»›i settings tá»‘i Æ°u
    dm = Flickr30kDataModule(
        data_dir='./data',
        batch_size=32,  # Batch size lá»›n hÆ¡n
        num_workers=8,  # Nhiá»u workers
        img_size=(224, 224),
        pin_memory=True,  # Pin memory cho GPU
        persistent_workers=True  # Giá»¯ workers
    )
    
    # Model
    model = OpenVocabLightningModule(config)
    
    # Callbacks tá»‘i Æ°u
    checkpoint_callback = ModelCheckpoint(
        monitor='val/mAP',
        mode='max',
        save_top_k=1,  # Chá»‰ lÆ°u 1 checkpoint tá»‘t nháº¥t
        filename='best-{epoch:02d}-{val/mAP:.3f}',
        save_last=True,
        every_n_epochs=5  # LÆ°u má»—i 5 epochs
    )
    
    early_stopping = EarlyStopping(
        monitor='val/total_loss',
        patience=5,  # Patience tháº¥p hÆ¡n
        mode='min',
        min_delta=0.001,
        verbose=True
    )
    
    lr_monitor = LearningRateMonitor(logging_interval='step')
    
    # Logger
    logger = TensorBoardLogger('lightning_logs', name='open_vocab_ultra_optimized')
    
    # Trainer vá»›i táº¥t cáº£ tá»‘i Æ°u hÃ³a
    trainer = pl.Trainer(
        max_epochs=15,  # Ãt epochs hÆ¡n
        accelerator='gpu',
        devices=1,
        strategy=DDPStrategy(find_unused_parameters=False) if torch.cuda.device_count() > 1 else 'auto',
        callbacks=[checkpoint_callback, early_stopping, lr_monitor],
        logger=logger,
        val_check_interval=0.5,
        log_every_n_steps=5,  # Log thÆ°á»ng xuyÃªn hÆ¡n
        precision=16,  # Mixed precision
        gradient_clip_val=1.0,  # Gradient clipping
        accumulate_grad_batches=1,
        deterministic=False,  # Cho phÃ©p non-deterministic Ä‘á»ƒ tÄƒng tá»‘c
        enable_progress_bar=True,
        enable_model_summary=True,
        fast_dev_run=False,
        limit_train_batches=1.0,
        limit_val_batches=0.3,  # Chá»‰ dÃ¹ng 30% validation
        sync_batchnorm=True,  # Sync batch norm
        replace_sampler_ddp=False,  # Tá»‘i Æ°u DDP
        detect_anomaly=False,  # Táº¯t anomaly detection Ä‘á»ƒ tÄƒng tá»‘c
    )
    
    # Train
    print("ğŸš€ Starting ULTRA OPTIMIZED training...")
    print(f"ğŸ“Š Model parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}")
    print(f"ğŸ“¦ Batch size: {dm.batch_size}")
    print(f"ğŸ–¼ï¸  Image size: {dm.img_size}")
    print(f"â±ï¸  Max epochs: {trainer.max_epochs}")
    print(f"ğŸ¯ Mixed precision: {config['use_amp']}")
    print(f"ğŸ’¾ Memory pinning: True")
    print(f"ğŸ”„ Persistent workers: True")
    
    trainer.fit(model, dm)

if __name__ == '__main__':
    import torch
    main()